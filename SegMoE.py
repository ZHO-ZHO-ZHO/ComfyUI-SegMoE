import os
import cv2
import torch
import numpy as np
from PIL import Image
import folder_paths

from huggingface_hub import hf_hub_download
from .segmoe import SegMoEPipeline

current_directory = os.path.dirname(os.path.abspath(__file__))
device = "cuda" if torch.cuda.is_available() else "cpu"


class SMoE_ModelLoader_Zho:
    def __init__(self):
        pass

    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "config_or_path": ("STRING", {"default": "segmind/SegMoE-4x2-v0"}),
            }
        }

    RETURN_TYPES = ("MODEL",)
    RETURN_NAMES = ("pipe",)
    FUNCTION = "load_model"
    CATEGORY = "ðŸŽ©SegMoE"
  
    def load_model(self, config_or_path):
        # Code to load the base model
        pipe = SegMoEPipeline(
            config_or_path,
            device = device,
        )
        return [pipe]


class SMoE_Generation_Zho:
    def __init__(self):
        pass

    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "pipe": ("MODEL",),
                "positive": ("STRING", {"default": "cosmic canvas, orange city background, painting of a chubby cat", "multiline": True}),
                "negative": ("STRING", {"default": "nsfw, bad quality, worse quality", "multiline": True}),
                "steps": ("INT", {"default": 50, "min": 1, "max": 100, "step": 1, "display": "slider"}),
                "guidance_scale": ("FLOAT", {"default": 5, "min": 0, "max": 10, "display": "slider"}),
                "width": ("INT", {"default": 1024, "min": 512, "max": 2048, "step": 32, "display": "slider"}),
                "height": ("INT", {"default": 1024, "min": 512, "max": 2048, "step": 32, "display": "slider"}), 
                "seed": ("INT", {"default": 0, "min": 0, "max": 0xffffffffffffffff}),
            }
        }

    RETURN_TYPES = ("IMAGE",)
    FUNCTION = "smoe_generate_image"
    CATEGORY = "ðŸŽ©SegMoE"
                       
    def smoe_generate_image(self, pipe, positive, negative, steps, guidance_scale, seed, width, height):
            
        generator = torch.Generator(device=device).manual_seed(seed)

        output = pipe(
            prompt=positive,
            negative_prompt=negative,
            num_inference_steps=steps,
            generator=generator,
            guidance_scale=guidance_scale,
            width=width,
            height=height,
            return_dict=False
            )

        # æ£€æŸ¥è¾“å‡ºç±»åž‹å¹¶ç›¸åº”å¤„ç†
        if isinstance(output, tuple):
            # å½“è¿”å›žçš„æ˜¯å…ƒç»„æ—¶ï¼Œç¬¬ä¸€ä¸ªå…ƒç´ æ˜¯å›¾åƒåˆ—è¡¨
            images_list = output[0]
        else:
            # å¦‚æžœè¿”å›žçš„æ˜¯ï¼Œéœ€è¦ä»Žä¸­æå–å›¾åƒ
            images_list = output.images

        # è½¬æ¢å›¾åƒä¸º torch.Tensorï¼Œå¹¶è°ƒæ•´ç»´åº¦é¡ºåºä¸º NHWC
        images_tensors = []
        for img in images_list:
            # å°† PIL.Image è½¬æ¢ä¸º numpy.ndarray
            img_array = np.array(img)
            # è½¬æ¢ numpy.ndarray ä¸º torch.Tensor
            img_tensor = torch.from_numpy(img_array).float() / 255.
            # è½¬æ¢å›¾åƒæ ¼å¼ä¸º CHW (å¦‚æžœéœ€è¦)
            if img_tensor.ndim == 3 and img_tensor.shape[-1] == 3:
                img_tensor = img_tensor.permute(2, 0, 1)
            # æ·»åŠ æ‰¹æ¬¡ç»´åº¦å¹¶è½¬æ¢ä¸º NHWC
            img_tensor = img_tensor.unsqueeze(0).permute(0, 2, 3, 1)
            images_tensors.append(img_tensor)

        if len(images_tensors) > 1:
            output_image = torch.cat(images_tensors, dim=0)
        else:
            output_image = images_tensors[0]

        return (output_image,)

NODE_CLASS_MAPPINGS = {
    "SMoE_ModelLoader_Zho": SMoE_ModelLoader_Zho,
    "SMoE_Generation_Zho": SMoE_Generation_Zho,
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "SMoE_ModelLoader_Zho": "ðŸŽ©SegMoE Model Loader",
    "SMoE_Generation_Zho": "ðŸŽ©SegMoE Generation",
}
